<!-- skal/ (pascal.massimino@gmail.com) 2024 -->
<!-- Curl Noise -->

<!DOCTYPE html>
<html>

<head>
<title>Curl Noise using WebGPU</title>
<link rel="stylesheet" href="../splats/style.css">
</head>

<body onload="main();">
<div id='main-area'>
  <center>
    <b><a href="https://www.cs.ubc.ca/~rbridson/docs/bridson-siggraph2007-curlnoise.pdf">Curl Noise</a> using WebGPU</b><br/>
    On <b>Chrome 113+</b>, you need to <a href='https://github.com/gpuweb/gpuweb/wiki/Implementation-Status'>enable</a>
    the <i>chrome://flags/#enable-webgpu-developer-features</i> !!<p>
    <div><canvas id="main-canvas"></canvas>
      <div id='info'><span id='fps' style='display:inline-block;width:90px;'></span></div>
      <form action="https://skal65535.github.io/">
        <input type="submit" value="skal 2024" id="skal-back"/>
      </form>
      <canvas id="progress-canvas" height='10px'></canvas>
    </div>
    <br/>
    <canvas id="side-canvas"></canvas>
  </center>
  Curl Noise
</div>
<script src="https://cdn.jsdelivr.net/npm/lil-gui@0.19"></script>
<script src="../common/matrix.js"></script>
<script src="../common/polyhedrons.js"></script>
<script src="../common/args.js"></script>
<script>
"use strict";

const kNoise = { 'curl': 0, 'rotation axis': 1, };

////////////////////////////////////////////////////////////////////////////////
// constants

const canvas = document.querySelector("#main-canvas");
const ctx = canvas.getContext("webgpu");

////////////////////////////////////////////////////////////////////////////////

const params = {
  poly: parse_arg_str('poly', 'icosahedron'),
  noise: parse_arg_str('noise', 'curl'),
  noise_amp: parse_arg('amp', 8.),
  spherify: parse_arg_bool('sph'),
  depth: parse_arg('depth', 60),
  wireframe: !parse_arg_bool('no-wireframe'),
  shadows: !parse_arg_bool('no-shadows'),
  sm_size: 1024,  // shadow-map size
  light_color: 0xfadede,
  light_pos: [.6, .8, .9,   0.],
  animate: false,

  // Camera
  fov: parse_arg('fov', 110., 30., 170.),
  model: { theta: 0., phi: 0., scale: 1., },
  cam: {
    dist: parse_arg('R', 1.25, 0.01, 10.),
    theta: 0.,
    phi: 30.0,
  },
  target: [0., 0., 0.],
  up: [0., 1., 0.],
  znear: 0.05,
  zfar: 100.,
  auto_rotate: !parse_arg_bool("no-rotate"),
  mouse: {on:false, x:0., y:0.},

  use_MSAA: parse_arg_bool('MSAA'),
  no_gui: parse_arg_bool('no-gui'),
  dbg: { trace: 0, timing: false,
         light: parse_arg_bool('light'),
         ortho: parse_arg_bool('ortho'),
         animate_light: parse_arg_bool('animate-light'), },
};

////////////////////////////////////////////////////////////////////////////////
// GUI setup

const GUI_change = async () => { await init({}); }  // parameter changed
const GUI_reload = async () => { await init({poly:true}); }

const GUI_init = () => {
  canvas.width  = parse_arg("w", innerWidth * .9);
  canvas.height = parse_arg("h", innerHeight * .8);

  if (params.no_gui) {
    render.gui = undefined;
    return;
  }
  render.gui = new lil.GUI({container: document.getElementById('#main-area'),
                            name: 'Curl Noise'});
  render.gui.add(params, 'poly', Object.keys(kPolys)).name('base polyhedron').listen().onChange(GUI_reload);
  render.gui.add(params, 'depth', 1, 256, 1).name('sub-div level').listen().onChange(GUI_reload);
//  render.gui.add(params, 'noise', Object.keys(kNoise)).listen().onChange(GUI_change);
  render.gui.add(params, 'noise_amp', 0., 20.).name('noise amplitude').listen().onChange(GUI_change);
  render.gui.add(params, 'wireframe').name('wireframe').listen().onChange(GUI_reload);
  render.gui.add(params, 'spherify').name('spherify').listen();
  render.gui.add(params, 'shadows').name('w/ shadows').listen().onChange(() => init({textures:true}));
  render.gui.add(params, 'use_MSAA').name('multisampling').listen().onChange(() => init({textures:true}));
  render.gui.addColor(params, 'light_color').name('light color').listen();
  const cam_folder = render.gui.addFolder('camera').close();
  cam_folder.add(params, 'fov', 0., 180., 5.).listen();
  cam_folder.add(params.cam, 'dist', 0.0001, 5., 0.01).name('distance').listen();
  cam_folder.add(params.cam, 'theta', 0., 360., 1.).listen();
  cam_folder.add(params.cam, 'phi', -180., 180., 1.).listen();
  const model_folder = render.gui.addFolder('model').close();
  model_folder.add(params.model, 'theta', 0., 360., 1.).listen();
  model_folder.add(params.model, 'phi', -180., 180., 1.).listen();
  model_folder.add(params, 'auto_rotate').name('auto rotate').listen();
  const dbg_folder = render.gui.addFolder('Debug').close();
  dbg_folder.add(params.dbg, 'trace', 0, 3, 1).name('trace level').listen();
  dbg_folder.add(params.dbg, 'timing').name('print timing').listen();
  dbg_folder.add(params.dbg, 'light').name('light depth').listen().onChange(GUI_reload);
  dbg_folder.add(params.dbg, 'ortho').name('ortho view').listen();
  dbg_folder.add(params.dbg, 'animate_light').name('animate light').listen();
  render.gui.add(render, 'txt_info').name('info').listen().disable();

  render.gui.domElement.style.top = '5%';
  render.gui.domElement.style.right = '3%';

  do_resize();
}

function GUI_Get(name) {
  for (const c of render.gui.controllersRecursive()) {
    if (c.property == name) return c;
  }
  return undefined;
}

////////////////////////////////////////////////////////////////////////////////
// event handling

window.addEventListener('pointermove', (event) => {
  if (event.target != canvas) return;
//  event.preventDefault();
  const bounds = canvas.getBoundingClientRect();
  const mouse_x = (event.clientX - bounds.left) / canvas.width;
  const mouse_y = (event.clientY -  bounds.top) / canvas.height;
  if (params.mouse.on) {
    if (event.shiftKey) {
      params.model.phi   += (params.mouse.y - mouse_y) * 140.;
      params.model.theta += (params.mouse.x - mouse_x) * 140.;
    } else {
      params.cam.phi   += (params.mouse.y - mouse_y) * 140.;
      params.cam.theta += (params.mouse.x - mouse_x) * 140.;
    }
  }
  params.mouse.x = mouse_x;
  params.mouse.y = mouse_y;
}, false);
window.addEventListener('pointerdown', (event) => {
  if (event.target == canvas) params.mouse.on = true;
});
window.addEventListener('pointerup', (event) => {
  params.mouse.on = false;
});
window.addEventListener('wheel', (event) => {
  if (event.target != canvas) return;
  event.preventDefault();
  const change_factor = (event.wheelDelta > 0) ? 1.05 : 1. / 1.05;
  if (event.shiftKey) {
    params.model.scale *= change_factor;
  } else {
    params.cam.dist *= change_factor;
  }
}, { passive: false });

window.addEventListener("resize", (e) => {
  canvas.width = window.innerWidth * .9;
  canvas.height = window.innerHeight * .8;
  do_resize();
});

function do_resize() {
  const pcanvas = document.getElementById("progress-canvas")
  pcanvas.width = .93 * canvas.width;
  init_textures(render);
}

////////////////////////////////////////////////////////////////////////////////
////// WebGPU init //////

const trace = (level, ...args) => {
  if (params.dbg.trace > level) console.log(args.join(' '));
}

function Oops(e) {
  // document.body.innerHTML = `Oops! <pre>${e}</pre>`;
  const side_canvas = document.querySelector("#side-canvas");
  side_canvas.style.display = 'inline-block';
  side_canvas.width = canvas.width * .8;
  const ctx = side_canvas.getContext('2d');
  ctx.fillStyle = '#f33';
  ctx.font = "bold 20px Arial";
  ctx.fillText('Oops!', 15, 30);
  ctx.font = "bold 12px Arial";
  ctx.fillText(e, 15, 55);
  throw Error(e);
}

const GPU_init = async () => {
  navigator.gpu || Oops("WebGPU not supported.");
  console.log("Navigator has GPU");

  const adapter = await navigator.gpu.requestAdapter();
  adapter || Oops("Couldn’t request WebGPU adapter.");
  console.log("WebGPU Adapter ok");

  render.device = await adapter.requestDevice();
  render.device || Oops("Couldn’t request WebGPU logical device.");
  console.log("WebGPU Device acquired.");

  function onDeviceError(event) {
    console.log("Something bad happened! Error type:", event.error.constructor.name);
    console.log("Error message:", event.error.message);
    if (render.device != undefined) {
      render.device.destroy();
      render.device = undefined;
    }
    stop_animation();
    Oops("Error caught while constructing the WebGPU device. See console.");
  }
  render.device.addEventListener('uncapturederror', onDeviceError);

  render.textureFormat = navigator.gpu.getPreferredCanvasFormat();
  render.target = [{
    format: render.textureFormat,
    blend: {
      color: {srcFactor: 'one', dstFactor: 'one-minus-dst-alpha', operation: 'add'},
      alpha: {srcFactor: 'one', dstFactor: 'one', operation: 'add'},
    },
  },];

  ctx.configure({device: render.device,
                 format: render.textureFormat,
                 usage: GPUTextureUsage.OUTPUT_ATTACHMENT,
                 alphaMode: 'premultiplied', });
}

////////////////////////////////////////////////////////////////////////////////
// Pipelines & Shaders (the cool stuff!)

const VertexIndexBuffer = [  // common index buffer
  { arrayStride: 4,
    stepMode: 'instance',
    attributes: [ { shaderLocation: 0, offset: 0, format: 'uint32', }, ],
  },
];

const struct_code = `
  struct Uniforms {
    model: mat4x3f,
    view: mat4x4f,
    proj: mat4x4f,
    light_proj: mat4x4f,
    light_pos: vec4f,
    light_color: u32,

    dim:  vec2f,   // screen dimension
    focal: vec2f,
    znear: f32,
    zfar:  f32,
    time:  f32,
    noise_amp:   f32,
    nb_idx: f32,
    nb_faces: f32,
    spherify: f32,
  }
  struct Out {
    @builtin(position) position: vec4f,
    @location(0) uv: vec2f,
    @location(1) @interpolate(flat) color: vec4f,
    @location(2) normal: vec4f,
    @location(3) pos3d: vec4f,
    @location(4) lpos: vec4f,  // light-depth position
  };
  struct Pos {
    p: vec3f,
    n: vec3f,
  };
`;
const group_0_code = `
  @group(0) @binding(0) var<uniform> params: Uniforms;
`;
const group_1_code = `
  @group(1) @binding(0) var<storage, read> vtx: array<vec4f>;
  @group(1) @binding(1) var<storage, read> faces: array<array<u32, 3>>;
  @group(1) @binding(2) var<storage, read> uv: array<vec2f>;
`;
const group_2_code = `
  @group(2) @binding(0) var light_depth: texture_depth_2d;
  @group(2) @binding(1) var cmp_sampler: sampler_comparison;
  @group(2) @binding(2) var depth_sampler: sampler;
`;
// displacement noise
const noise_code = `
    const ex = vec3i(1,0,0);
    const ey = vec3i(0,1,0);
    const ez = vec3i(0,0,1);

    fn Hash1f(p: u32) -> f32 {
      var P = (p << 13) ^ p;
      P = P * (P * P * 15731 + 789221) + 1376312589;
      return bitcast<f32>((P >> 9) | 0x3f800000) - 1.;
    }
    fn Hash3f(p: u32) -> vec3f {
      return vec3f(Hash1f(p), Hash1f(p + 1423), Hash1f(p + 124453));
    }
    fn noise1f(p: vec3i) -> f32 { return Hash1f(u32(dot(p, vec3i(3, 113, 311)))); }
    fn lerp(p: vec3i, alpha: f32) -> f32 { return mix(noise1f(p), noise1f(p + ex), alpha); }
    fn noise1d(p: vec3f) -> f32 {
      let X = vec3i(floor(p));
      let dX = fract(p);
      let n00 = lerp(X, dX.x);
      let n10 = lerp(X + ey, dX.x);
      let n01 = lerp(X + ez, dX.x);
      let n11 = lerp(X + ey + ez, dX.x);
      let m0 = mix(n00, n10, dX.y);
      let m1 = mix(n01, n11, dX.y);
      return mix(m0, m1, dX.z);
    }
    fn noise3d(p: vec3f) -> vec3f {
      return vec3f(noise1d(p),
                   noise1d(p * vec3f(1.03, 0.98, 1.07)),
                   noise1d(p * vec3f(2.01, 0.97, 0.99)));
    }
`;
const displace_code = `
    fn rotation_matrix(axis: vec3f, angle: f32) -> mat3x3f {
      let c = cos(angle);
      let S = axis * sin(angle);
      let C = axis * (1. - c);
      return mat3x3f(vec3f(C.x * axis + vec3f(   c, -S.z,  S.y)),
                     vec3f(C.y * axis + vec3f( S.z   , c, -S.x)),
                     vec3f(C.z * axis + vec3f(-S.y,  S.x,    c)));
    }
    fn fnoise(p: vec3f) -> vec3f {
      let m = rotation_matrix(normalize(vec3f(.4, .3, -.1)), .1);
      var P = p;
      var               out  =        noise3d(P);
//      P = m * P * 2.02; out += .500 * noise3d(P);
//      P = m * P * 2.05; out += .250 * noise3d(P);
//      P = m * P * 1.98; out += .125 * noise3d(P);
      return out;
    }
    // Rodrigues's formula: https://en.wikipedia.org/wiki/Rodrigues%27_rotation_formula
    fn rotate3(p: vec3f, axis: vec3f, angle: f32) -> vec3f {
      // return cos(angle) * p + sin(angle) * cross(axis, p) + (1. - cos(angle)) * dot(p, axis) * axis;
      return rotation_matrix(axis, angle) * p;
    }
    fn Move(p: vec3f, phase: vec3f) -> vec3f {
      let axis = normalize(fnoise(p * 2.53 + phase));
      let angle = 2. * 3.1415926 * noise1d(p * 3.01 + phase);
      return p + rotate3(p, axis, angle) * params.noise_amp;
    }
    fn MakeOrthogonal(v: vec3f) -> vec3f {   // http://sam.hocevar.net/blog/2013/09/
      if (abs(v.x) > abs(v.z)) { return normalize(vec3f(-v.y, v.x, 0.)); }
      return normalize(vec3f(0., -v.z, v.y));
    }
    fn Displace(p: ptr<function, Pos>, t: f32) {
      let phase = vec3f(t, t * 1.01, t * .96);
      let P = (*p).p;
      let N = (*p).n;
      const eps : f32 = 1e-3;
      let t1 = MakeOrthogonal(N);   // tangent
      let t2 = cross(N, t1);        // bi-tangent
      let p0 = Move(P, phase);
      let p1 = Move(P + t1 * eps, phase);
      let p2 = Move(P + t2 * eps, phase);
      let n0 = normalize(cross(p1 - p0, p2 - p0));
      (*p).p = p0;
      (*p).n = n0;
    }
    fn GetPos(vtx_idx: u32, face_idx: u32) -> Pos {
      let face = faces[face_idx];
      let p0 = vtx[face[0]].xyz;
      let p1 = vtx[face[1]].xyz;
      let p2 = vtx[face[2]].xyz;
      let n = normalize(cross(p1 - p0, p2 - p1));
      let m = mat3x3f(p0, p1, p2);
      let UV = uv[vtx_idx];
      let w = vec3f(UV, 1. - UV.x - UV.y);
      // interpolate to p0 * alpha + p1 * beta + p2 * gamma;
      // (and maybe project on the unit sphere):
      var p : Pos;
      p.p = m * w;
      p.n = n;
      if (params.spherify > 0.) {
        p.p = normalize(p.p);
        p.n = p.p;
      }
      Displace(&p, params.time * 0.002);         // + rotational noise
      p.p = params.model * vec4f(p.p, 1.);
      p.n = params.model * vec4f(p.n, 0.);   // no scaling, so transp(inv(m)) = m
      return p;
    }
`;

function create_vtx_pipeline(render) {
  const vtx_code = `
    ${struct_code}
    ${group_0_code}
    ${group_1_code}

    ${noise_code}
    ${displace_code}

    @vertex fn vtx_main(@builtin(vertex_index) vtx_idx: u32,
                        @builtin(instance_index) face_idx: u32,  ) -> Out {
      var p = GetPos(vtx_idx, face_idx);
      var pos3d = vec4f(p.p, 1.);
      var normal = normalize(params.view * vec4f(p.n, 0.));
      var vpos = params.proj * params.view * pos3d;

      var output : Out;
      output.position = vpos;
      output.pos3d = pos3d;
      output.normal = normal;
      output.uv = uv[vtx_idx];
      output.color = vec4f(Hash3f(face_idx), 1.);
      let l = params.light_proj * vec4f(p.p, 1.);
      output.lpos = vec4f(l.xy * .5 + vec2f(.5, .5), l.z, l.w);
      return output;
    }`;
  const fragment_code = `
    @fragment fn frag_main(s: Out) -> @location(0) vec4f {
      let ldir = normalize(params.light_pos.xyz - s.pos3d.xyz);
      let d = max(0., dot(ldir, s.normal.xyz));
      var color = .3 * s.color + d * unpack4x8unorm(params.light_color);
      let r = normalize(reflect(s.pos3d, s.normal).xyz);
      let highlight = 1.5 * vec4f(1., 1., .8, 1.) * pow(max(0., dot(r, ldir)), 60.);
      color += highlight;
      return vec4f(color.rgb, 1.);
    }
  `;
  const shadow_fragment_code = `
    ${group_2_code}

    @fragment fn frag_main(s: Out) -> @location(0) vec4f {
      _ = light_depth;
      _ = cmp_sampler;
      _ = depth_sampler;
      var sum = 0.;
      sum += textureSampleCompare(
        light_depth, cmp_sampler, s.lpos.xy, s.lpos.z - 0.007);
      sum /= 1.;

      let ldir = normalize(params.light_pos.xyz - s.pos3d.xyz);
      var d = 0.2 + sum * max(0., dot(ldir, s.normal.xyz));
      // return vec4f(sum, sum, sum, 1.);
      // return vec4f(s.color.rgb * min(d, 1.), 1.);
      let z = textureSample(light_depth, depth_sampler, s.uv); // s.lpos.xy);
      return vec4f(z, z, 1., 1.);
    }
  `;

  const vtx_module = render.device.createShaderModule(
    { code: vtx_code + (params.shadows ? shadow_fragment_code : fragment_code) });
  render.pipeline = render.device.createRenderPipeline({
    layout: 'auto',
    vertex: {
      module: vtx_module,
      entryPoint: 'vtx_main',
      buffers: VertexIndexBuffer,
    },
    fragment: {
      module: vtx_module,
      entryPoint: 'frag_main',
      targets: render.target,
    },
    primitive: {
      topology: 'triangle-strip',
      stripIndexFormat: 'uint32',
      cullMode: 'none',
    },
    depthStencil: {
      depthWriteEnabled: true,
      depthCompare: 'greater',
      format: 'depth24plus',
    },
    multisample: { count: (params.use_MSAA ? 4 : 1), },
  });
  render.bind_group_0 = render.device.createBindGroup({
    layout: render.pipeline.getBindGroupLayout(0),
    entries: render.GPU.uniform_entries,
  });
  render.bind_group_1 = render.device.createBindGroup({
    layout: render.pipeline.getBindGroupLayout(1),
    entries: render.GPU.base_entries,
  });
  if (params.shadows) {
    render.bind_group_2 = render.device.createBindGroup({
      layout: render.pipeline.getBindGroupLayout(2),
      entries: render.GPU.light_entries,
    });
  }
}

function create_cube_pipeline(render) {
  const vtx_code = `
    ${struct_code}
    ${group_0_code}
    ${noise_code}
    const kVtxs = array<u32, 24>(
        0, 1, 2, 3,
        4, 6, 5, 7,
        0, 4, 1, 5,
        3, 7, 2, 6,
        0, 2, 4, 6,
        3, 1, 7, 5);
    const kNormals = array<vec4f, 6>(
        vec4f( 0.,-1., 0., 0.), vec4f( 0., 1., 0., 0.),
        vec4f( 0., 0.,-1., 0.), vec4f( 0., 0., 1., 0.),
        vec4f(-1., 0., 0., 0.), vec4f( 1., 0., 0., 0.));
    const kColors = array<vec4f, 6>(
        vec4f( 0., 1., 0., 1.), vec4f( 0., .5, 0., 1.),
        vec4f( 0., 0., 1., 1.), vec4f( 0., 0., .5, 1.),
        vec4f( 1., 0., 0., 1.), vec4f( .5, 0., 0., 1.));
    @vertex fn vtx_main(@builtin(vertex_index) vtx_idx: u32,
                        @builtin(instance_index) face: u32) -> Out {
      let id = kVtxs[vtx_idx + face * 4];
      var pos = vec3f(1., 1., 1.) * 3.;
      if ((id & 1) != 0) { pos.x = -pos.x; }
      if ((id & 2) != 0) { pos.z = -pos.z; }
      if ((id & 4) != 0) { pos.y = -pos.y; }
      var output : Out;
      output.pos3d = vec4f(pos, 1.);
      output.position = params.proj * params.view * output.pos3d;
      output.normal = kNormals[face];
      output.color = kColors[face];
      return output;
    }`;
  const fragment_code = `
    @fragment fn frag_main(s: Out) -> @location(0) vec4f {
      let ldir = normalize(params.light_pos.xyz - s.pos3d.xyz);
      let d = 0.5 * max(0., dot(ldir, s.normal.xyz));
      let lcol = unpack4x8unorm(params.light_color);
      return vec4f(s.color.rgb * .6 + d * lcol.rgb, 1.);
    }
  `;

  const vtx_module = render.device.createShaderModule(
    { code: vtx_code + fragment_code });
  render.cube_pipeline = render.device.createRenderPipeline({
    layout: 'auto',
    vertex: { module: vtx_module, entryPoint: 'vtx_main', },
    fragment: {
      module: vtx_module,
      entryPoint: 'frag_main',
      targets: render.target,
    },
    primitive: {
      topology: 'triangle-strip',
      stripIndexFormat: 'uint32',
      cullMode: 'back',
    },
    depthStencil: {
      depthWriteEnabled: true,
      depthCompare: 'greater',
      format: 'depth24plus',
    },
    multisample: { count: (params.use_MSAA ? 4 : 1), },
  });
  render.cube_bind_group_0 = render.device.createBindGroup({
    layout: render.cube_pipeline.getBindGroupLayout(0),
    entries: render.GPU.uniform_entries,
  });
}

function create_wireframe_pipeline(render) {
  const code = `
    ${struct_code}
    ${group_0_code}
    ${group_1_code}

    ${noise_code}
    ${displace_code}

    @vertex fn vtx_main(@builtin(vertex_index) vtx_idx: u32,
                        @builtin(instance_index) face_idx: u32,  ) -> Out {
      let p = GetPos(vtx_idx, face_idx);

      var output : Out;
      output.position = params.proj * params.view * vec4f(p.p, 1.);
      let g = f32(face_idx) / f32(params.nb_faces) + .8;
      let color = abs(noise3d(vec3f(g, 1., g) * 32.153)) * .8 + .5;
      output.color = vec4f(color, 1.);
      return output;
    }
    @fragment fn frag_main(s: Out) -> @location(0) vec4f {
      return vec4f(s.color.rgb * s.position.w, 1.);
    }
  `;

  const vtx_module = render.device.createShaderModule({ code: code });
  render.pipeline = render.device.createRenderPipeline({
    layout: 'auto',
    vertex: {
      module: vtx_module,
      entryPoint: 'vtx_main',
      buffers: VertexIndexBuffer,
    },
    fragment: {
      module: vtx_module,
      entryPoint: 'frag_main',
      targets: render.target,
    },
    primitive: {
      topology: 'line-strip',
      stripIndexFormat: 'uint32',
      cullMode: 'none',
    },
    depthStencil: {
      depthWriteEnabled: true,
      depthCompare: 'greater',
      format: 'depth24plus',
    },
    multisample: { count: (params.use_MSAA ? 4 : 1), },
  });
  render.bind_group_0 = render.device.createBindGroup({
    layout: render.pipeline.getBindGroupLayout(0),
    entries: render.GPU.uniform_entries,
  });
  render.bind_group_1 = render.device.createBindGroup({
    layout: render.pipeline.getBindGroupLayout(1),
    entries: render.GPU.base_entries,
  });
}

function create_light_pipeline(render) {
  const shadow_code = `
    ${struct_code}
    ${group_0_code}
    ${group_1_code}

    ${noise_code}
    ${displace_code}

    @vertex fn vtx_main(@builtin(vertex_index) vtx_idx: u32,
                        @builtin(instance_index) face_idx: u32,  )
        -> @builtin(position) vec4f {
      var p = GetPos(vtx_idx, face_idx);
//      return vec4f(p.p, 1.);
      return params.light_proj * vec4f(p.p, 1.);
    }
  `;
  const shadow_module = render.device.createShaderModule({ code: shadow_code });
  render.light_pipeline = render.device.createRenderPipeline({
    layout: 'auto',
    vertex: {
      module: shadow_module,
      entryPoint: 'vtx_main',
      buffers: VertexIndexBuffer,
    },
    primitive: {
      topology: params.wireframe ? 'line-strip' : 'triangle-strip',
      stripIndexFormat: 'uint32',
      cullMode: 'none',  // 'back'?
    },
    depthStencil: {
      depthWriteEnabled: true,
      depthCompare: 'greater',
      format: 'depth32float',
    },
    multisample: { count: 1, },
  });
  render.light_bind_group_0 = render.device.createBindGroup({
    layout: render.light_pipeline.getBindGroupLayout(0),
    entries: render.GPU.uniform_entries,
  });
  render.light_bind_group_1 = render.device.createBindGroup({
    layout: render.light_pipeline.getBindGroupLayout(1),
    entries: render.GPU.base_entries,
  });
}

function create_dbg_pipeline(render) {
  const dbg_code = `
    ${struct_code}
    ${group_0_code}
    ${group_1_code}
    ${group_2_code}

    struct Vtx {
      @builtin(position) pos: vec4f,
      @location(0) uv: vec2f,
    }
    @vertex fn vtx_main(@location(0) pos: vec3f,
                        @location(1) uvw: vec3f, ) -> Vtx {
      _ = cmp_sampler;
      _ = vtx[0];
      _ = faces[0];
      _ = uv[0];
      return Vtx(params.proj * params.view * vec4f(pos, 1.), uvw.xy);
    }
    @fragment fn frag_main(@location(0) uv: vec2f, ) -> @location(0) vec4f {
      let z = textureSample(light_depth, depth_sampler, uv);
      return vec4f(z, z, 1., 1.);
    }
  `;

  const dbg_module = render.device.createShaderModule({ code: dbg_code });
  render.dbg_pipeline = render.device.createRenderPipeline({
    layout: 'auto',
    vertex: {
      module: dbg_module,
      entryPoint: 'vtx_main',
      buffers: [ { arrayStride: 6 * 4,
                   attributes: [ { shaderLocation: 0, offset: 0 * 4, format: 'float32x3', },
                                 { shaderLocation: 1, offset: 3 * 4, format: 'float32x3', }, ],
                 } ],
    },
    fragment: {
      module: dbg_module,
      entryPoint: 'frag_main',
      targets: render.target,
    },
    primitive: {
      topology: 'triangle-strip',
      cullMode: 'none',  // 'back'?
    },
    depthStencil: {
      depthWriteEnabled: true,
      depthCompare: 'greater',
      format: 'depth24plus',
    },
    multisample: { count: (params.use_MSAA ? 4 : 1), },
  });
  render.dbg_bind_group_0 = render.device.createBindGroup({
    layout: render.dbg_pipeline.getBindGroupLayout(0),
    entries: render.GPU.uniform_entries,
  });
  render.dbg_bind_group_1 = render.device.createBindGroup({
    layout: render.dbg_pipeline.getBindGroupLayout(1),
    entries: render.GPU.base_entries,
  });
  render.dbg_bind_group_2 = render.device.createBindGroup({
    layout: render.dbg_pipeline.getBindGroupLayout(2),
    entries: render.GPU.light_entries,
  });
}

function create_pipelines(render) {
  render.device || Oops("Can't create pipelines without a device!");
  if (params.wireframe) create_wireframe_pipeline(render);
  else create_vtx_pipeline(render);
  create_cube_pipeline(render);
  if (params.shadows) {
    create_light_pipeline(render);
    if (params.dbg.light) create_dbg_pipeline(render);
  }
}

////////////////////////////////////////////////////////////////////////////////
// Create the data buffers

async function init_textures(render) {
  if (render.multisample_texture != undefined) {
    render.multisample_texture.destroy();
    render.multisample_texture = undefined;
  }
  if (params.use_MSAA) {
    render.multisample_texture = render.device.createTexture({
      label: 'multisample',
      size: [canvas.width, canvas.height],
      sampleCount: 4,
      format: render.textureFormat,
      usage: GPUTextureUsage.RENDER_ATTACHMENT,
    });
  }
  render.depth_texture = render.device.createTexture({
    label: 'depth',
    size: [canvas.width, canvas.height],
    format: 'depth24plus',
    usage: GPUTextureUsage.RENDER_ATTACHMENT,
    sampleCount: (params.use_MSAA ? 4 : 1),
  });

  if (params.shadows) {
    render.light_depth = render.device.createTexture({
      label: 'light-depth',
      size: [params.sm_size, params.sm_size, 1],
      format: 'depth32float',
      usage: GPUTextureUsage.RENDER_ATTACHMENT | GPUTextureUsage.TEXTURE_BINDING,
      sampleCount: 1,
    });
    render.GPU.light_entries = [
        { binding: 0, resource: render.light_depth.createView(), },
        { binding: 1, resource: render.device.createSampler({ compare: 'greater', }), },
        { binding: 2, resource: render.device.createSampler({
            addressModeU: "clamp-to-edge", addressModeV: "clamp-to-edge",
            magFilter: "linear", minFilter: "linear", mipmapFilter: "linear",
          }), },
    ];
  } else if (render.light_depth) {
    render.light_depth.destroy();
    render.light_depth = null;
    render.GPU.light_entries = null;
  }
  if (render.gui) {
    GUI_Get('light').enable(params.shadows);
  }
}

// END OF GPU PART
////////////////////////////////////////////////////////////////////////////////

function compute_frame_params() {
  const aspect = canvas.width / canvas.height;
  render.fx = 1. / Math.tan(params.fov * Math.PI / 360.);
  render.fy = aspect * render.fx;
  render.proj =
    params.dbg.ortho ? ortho(render.fx, render.fy, params.znear, params.zfar)
                     : perspective(render.fx, render.fy, params.znear, params.zfar);

  const theta = params.cam.theta * Math.PI / 180.;
  const phi = params.cam.phi * Math.PI / 180.;
  const cam_pos = [ params.cam.dist * Math.cos(theta) * Math.cos(phi),
                    params.cam.dist *                   Math.sin(phi),
                    params.cam.dist * Math.sin(theta) * Math.cos(phi), ];
  render.view = look_at(cam_pos, params.target, params.up);

  render.model = multiply4(
    multiply4(rotation([0.,-1., 0.], params.model.theta * Math.PI / 180.),
              rotation([0., 0., 1.], params.model.phi * Math.PI / 180.)),
    id4([params.model.scale, params.model.scale, params.model.scale]));

  render.light_pos = new Float32Array(params.light_pos);
  if (params.dbg.animate_light) {
    render.light_pos =
      multiply4(rotation([0., 1., 0.], render.tick * Math.PI / 180.),
                render.light_pos);
console.log(render.tick);
  }
  render.light_proj = multiply4(
    look_at(cam_pos, params.target, params.up),
    ortho(1., 1., 0., 2.),
  );
//  render.light_proj = ortho(1., 1., .0, 2.);
  render.light_color = new Uint32Array([params.light_color]);
}

////////////////////////////////////////////////////////////////////////////////
// CPU -> GPU transfer

function transmit_uniforms() {
  render.device.queue.writeBuffer(render.GPU.uniforms,  0 * 4, render.model);
  render.device.queue.writeBuffer(render.GPU.uniforms, 16 * 4, render.view);
  render.device.queue.writeBuffer(render.GPU.uniforms, 32 * 4, render.proj);
  render.device.queue.writeBuffer(render.GPU.uniforms, 48 * 4, render.light_proj);
  render.device.queue.writeBuffer(render.GPU.uniforms, 64 * 4, render.light_pos);
  render.device.queue.writeBuffer(render.GPU.uniforms, 68 * 4, render.light_color);

  render.device.queue.writeBuffer(
    render.GPU.uniforms, 70 * 4,
      new Float32Array([ canvas.width, canvas.height,
                         render.fx, render.fy,
                         params.znear, params.zfar,
                         render.tick,
                         params.noise_amp / 50.,
                         render.nb_idx,
                         render.nb_faces,
                         params.spherify, ]));
}

////////////////////////////////////////////////////////////////////////////////
// Animation loop

async function frame() {
  const time_stamp = performance.now();
  if (render.time_stamp) {
    const delta_t = time_stamp - render.time_stamp;
    if (delta_t > 1.) {
      const new_fps = 1000. / delta_t;
      render.fps = Math.round(render.fps * 0.8 + new_fps * 0.2);
    }
    document.getElementById("fps").innerText = render.fps.toFixed(1) + " fps";
  }
  render.time_stamp = time_stamp;

  performance.mark("webgpu start");

  compute_frame_params();

  transmit_uniforms();

  const encoder = render.device.createCommandEncoder();

  if (params.dbg.timing) console.time("GPU");

  if (params.shadows) {
    const light_depth_view = render.light_depth.createView({label: 'LIGHT-DEPTH'});
    const light_pass_descriptor = {
      colorAttachments: [],
      depthStencilAttachment: {
        view: light_depth_view,
        depthClearValue: 0.0, depthLoadOp: 'clear', depthStoreOp: 'store',
      },
    };
    const light_pass = encoder.beginRenderPass(light_pass_descriptor);
    light_pass.setPipeline(render.light_pipeline);
    light_pass.setBindGroup(0, render.light_bind_group_0);
    light_pass.setBindGroup(1, render.light_bind_group_1);
    light_pass.setVertexBuffer(0, render.GPU.vtx);
    light_pass.setIndexBuffer(render.GPU.idx, 'uint32');
    light_pass.drawIndexed(render.nb_idx, render.nb_faces);
    light_pass.end();
  }

  if (render.nb_idx > 0) {
    const pass_descriptor = {
      colorAttachments: [
        { view: undefined,
          resolveTarget: undefined,
          clearValue: {r:0., g:0., b:0., a:0.}, loadOp: 'clear', storeOp: 'store', },
      ],
      depthStencilAttachment: {
        view: render.depth_texture.createView(),
        depthClearValue: 0.0, depthLoadOp: 'clear', depthStoreOp: 'store',
      },
    };
    const canvas_view = ctx.getCurrentTexture().createView({label: 'CANVAS'});
    if (params.use_MSAA) {
      const MSAA_view = render.multisample_texture.createView({label: 'MULTISAMPLE'});
      pass_descriptor.colorAttachments[0].view = MSAA_view;
      pass_descriptor.colorAttachments[0].resolveTarget = canvas_view;
    } else {
      pass_descriptor.colorAttachments[0].view = canvas_view;
    }
    {
      const render_pass = encoder.beginRenderPass(pass_descriptor);
      render_pass.setPipeline(render.pipeline);
      render_pass.setBindGroup(0, render.bind_group_0);
      render_pass.setBindGroup(1, render.bind_group_1);
      if (params.shadows) render_pass.setBindGroup(2, render.bind_group_2);
      render_pass.setVertexBuffer(0, render.GPU.vtx);
      render_pass.setIndexBuffer(render.GPU.idx, 'uint32');
      render_pass.drawIndexed(render.nb_idx, render.nb_faces);
      render_pass.end();
    }

    pass_descriptor.depthStencilAttachment.depthLoadOp = 'load';
    pass_descriptor.colorAttachments[0].loadOp = 'load';

    if (true) {
      const render_pass = encoder.beginRenderPass(pass_descriptor);
      render_pass.setPipeline(render.cube_pipeline);
      render_pass.setBindGroup(0, render.cube_bind_group_0);
//      if (params.shadows) render_pass.setBindGroup(2, render.cube_bind_group_2);
      render_pass.draw(4, 6);
      render_pass.end();
    }
    if (params.shadows && params.dbg.light) {
      const render_pass = encoder.beginRenderPass(pass_descriptor);
      render_pass.setPipeline(render.dbg_pipeline);
      render_pass.setBindGroup(0, render.dbg_bind_group_0);
      render_pass.setBindGroup(1, render.dbg_bind_group_1);
      render_pass.setBindGroup(2, render.dbg_bind_group_2);
      render_pass.setVertexBuffer(0, render.GPU.dbg_plane);
      render_pass.draw(4);
      render_pass.end();
    }
  }

  render.device.queue.submit([encoder.finish()]);

  if (params.dbg.timing) console.timeEnd("GPU");
  performance.mark("webgpu end");
  performance.measure("webgpu", "webgpu start", "webgpu end");

  if (params.auto_rotate) params.model.theta -= 0.07;
  ++render.tick;
  render.loop_id = requestAnimationFrame(frame);
}

function stop_animation() {
  if (render.loop_id != undefined) {
    cancelAnimationFrame(render.loop_id);
    render.loop_id = undefined;
  }
}

////////////////////////////////////////////////////////////////////////////////

var render = {  /* Run-time data: device, uniforms, pipeline... */
  device: undefined,
  textureFormat: undefined,
  target: undefined,

  GPU: {   // data sent to GPU
    vtx:     null,     // base vtx
    faces:   null,     // faces
    idx:     null,     // per-face tesselation sub-idx
    uv:      null,     // barycentric coordinate of sub-idx
    colors:    null,   // u32
    uniforms:  null,
    uniform_entries: null,
    base_entries: null,
    light_entries: null,
    dbg_plane: null,
  },
  nb_vtx: 0,
  nb_faces: 0,
  nb_idx: 0,

  pipeline: null,
  light_pipeline: null,
  dbg_pipeline: null,

  // per-frame params
  model: undefined,
  view: undefined,
  proj: undefined,
  light_pos: undefined,
  light_proj: undefined,
  light_color: undefined,
  fx: undefined,
  fy: undefined,

  // side info
  fps: 60.,
  time_stamp: undefined,
  txt_info: "",
  loop_id: undefined,  // id for animation loop
  tick: 0.,

  gui: undefined,
};

////////////////////////////////////////////////////////////////////////////////
// Sub-divisions

function MakeSubs(depth) {
  const UVs = [];
  for (let i = 0; i <= depth; ++i) {
    for (let j = 0; j <= i; ++j) {
      const u = i / depth, v = j / depth;
      UVs.push(1 - u, u - v);
    }
  }

  const idx = [];   // This one could be pre-calc'd up to max_depth
  for (let i = 0; i < depth; ++i) {
    const s = i * (i + 1) / 2;
    const t = (i + 2) * (i + 1) / 2;
    idx.push(t);
    if (i > 0) idx.push(t);
    for (let j = 0; j <= i; ++j) {
      idx.push(s + j, t + j + 1);
    }
    if (params.wireframe) {
      for (let j = 0; j <= i; ++j) idx.push(t + i - j);
      if (i + 1 < depth) idx.push(t);
    } else {
      if (i + 1 < depth) idx.push(t + i + 1);  // repeat last
    }
  }
  return [idx, UVs];
}

function Create_GPU_Buffer(render, src_buf, buf_usage = 0, as_u32 = false) {
  const gpu_buf = render.device.createBuffer({
    size: src_buf.length * 4,
    usage: buf_usage | GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST,
    mappedAtCreation: true,
  });
  if (as_u32) {
    new Uint32Array(gpu_buf.getMappedRange()).set(src_buf);
  } else {
    new Float32Array(gpu_buf.getMappedRange()).set(src_buf);
  }
  gpu_buf.unmap();
  return gpu_buf;
}

async function set_poly(polyhedron_name) {
  const poly = kPolys[polyhedron_name];

  render.nb_vtx = poly.vtx.length / 4;
  render.GPU.vtx = Create_GPU_Buffer(render, poly.vtx, GPUBufferUsage.VERTEX);
  render.nb_faces = poly.faces.length / 3;
  render.GPU.faces = Create_GPU_Buffer(render, poly.faces, 0, true);

  const [idx, uv] = MakeSubs(params.depth);
  render.nb_idx = idx.length;
  render.GPU.idx = Create_GPU_Buffer(render, idx, GPUBufferUsage.INDEX, true);
  render.GPU.uv = Create_GPU_Buffer(render, uv);

  // uniforms buffer
  render.GPU.uniforms = render.device.createBuffer({
    size: 84 * 4,
    usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,
  });
  render.GPU.uniform_entries = [
    { binding: 0, resource: { buffer: render.GPU.uniforms, }, },
  ];

  render.GPU.base_entries = [
    { binding: 0, resource: { buffer: render.GPU.vtx, }, },
    { binding: 1, resource: { buffer: render.GPU.faces, }, },
    { binding: 2, resource: { buffer: render.GPU.uv, }, },
  ];

  // Background Cube
  const cube = kPolys['cube'];
  render.GPU.cube_vtx = Create_GPU_Buffer(render, cube.vtx, GPUBufferUsage.VERTEX);
  render.GPU.cube_faces = Create_GPU_Buffer(render, cube.faces, 0, true);
  render.GPU.cube_entries = [
    { binding: 0, resource: { buffer: render.GPU.uniforms, }, },
  ];

  if (params.dbg.light) {
    const Y = 0.3;
    render.GPU.dbg_plane = Create_GPU_Buffer(render,
      new Float32Array([ -1, Y, -1.,  0., 0.,    0.,
                          1, Y, -1.,  1., 0.,    0.,
                         -1, Y,  1.,  0., 1.,    0.,
                          1, Y,  1.,  1., 1.,    0.]),
      GPUBufferUsage.VERTEX);
  }
  render.tick = 0.;
  render.txt_info = "vtx:" + render.nb_vtx + " faces:" + render.nb_faces
                  + " idx:" + render.nb_idx + " uv:" + (uv.length / 2);
}

async function init(what) {
  render.device || Oops("Initialization failed. Is WebGPU supported and " +
                        "<a href='https://github.com/gpuweb/gpuweb/wiki/Implementation-Status'>enabled</a>?");
  stop_animation();

  if (what.poly) {
    await set_poly(params.poly);
  }
  if (what.textures) {
    await init_textures(render);
  }
  create_pipelines(render);

  frame();    // start animation loop
}

async function main() {
  try {
    await GPU_init();
    GUI_init();
    await init({poly:true, textures:true,});
  } catch(e) { Oops(e); }
}

</script>

</body>
</html>
