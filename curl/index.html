<!-- skal/ (pascal.massimino@gmail.com) 2024 -->
<!-- Curl Noise -->

<!DOCTYPE html>
<html>

<head>
<title>Curly thing using WebGPU</title>
<link rel="stylesheet" href="../splats/style.css">
</head>

<body onload="main();">
<div id='main-area'>
  <center>
    <b><a href="https://www.cs.ubc.ca/~rbridson/docs/bridson-siggraph2007-curlnoise.pdf">Curl Noise</a> using WebGPU</b><br/>
    On <b>Chrome 113+</b>, you need to <a href='https://github.com/gpuweb/gpuweb/wiki/Implementation-Status'>enable</a>
    the <i>chrome://flags/#enable-webgpu-developer-features</i> !!<p>
    <div><canvas id="main-canvas"></canvas>
      <div id='info'><span id='fps' style='display:inline-block;width:90px;'></span></div>
      <form action="https://skal65535.github.io/">
        <input type="submit" value="skal 2024" id="skal-back"/>
      </form>
      <canvas id="progress-canvas" height='10px'></canvas>
    </div>
    <br/>
    <canvas id="side-canvas"></canvas>
  </center>
</div>
<script src="https://cdn.jsdelivr.net/npm/lil-gui@0.19"></script>
<script src="../common/matrix.js"></script>
<script src="../common/polyhedrons.js"></script>
<script src="../common/args.js"></script>
<script src="../common/utils.js"></script>
<script>
"use strict";

const kNoise = { 'curl': 0, 'rotation axis': 1, };
const kShowMaps = [ 'None', 'Shadow', 'Depth' ];

////////////////////////////////////////////////////////////////////////////////
// constants

const canvas = document.querySelector("#main-canvas");
const ctx = canvas.getContext("webgpu");

////////////////////////////////////////////////////////////////////////////////

const params = {
  poly: parse_arg_str('poly', 'icosahedron'),
  noise: parse_arg_str('noise', 'curl'),
  noise_amp: parse_arg('amp', 8.),
  spherify: parse_arg_bool('sph'),
  depth: parse_arg('depth', 60),
  wireframe: parse_arg_bool('wireframe'),
  sm_size: parse_arg('sm', 1024),  // shadow-map size
  light_color: 0xfadede,
  light_pos: [1.3, -1.8, 1.,   1.],
  animate: parse_arg_bool('animate'),
  post_proc: !parse_arg_bool('no-post'),
  funky: parse_arg_bool('funky'),
  specular: parse_arg('specular', 1.2),
  nb_shadow_samples: parse_arg('shadow-samples', 64.),
  shadow_extent: parse_arg('shadow-extent', 30.),
  shadow_jitter: parse_arg('shadow-jitter', 1.),
  do_shadow: !parse_arg_bool('no-shadow'),
  show_box: !parse_arg_bool('no-box'),

  // Camera
  model: { theta: 0., phi: 0., scale: 1., },
  cam: {
    dist: parse_arg('R', 2.0, 0.01, 10.),
    theta: parse_arg('theta', -5.),
    phi: parse_arg('phi', -5.0),
    fov: parse_arg('fov', 110., 30., 170.),
    znear: parse_arg('znear', 0.01),
    zfar: parse_arg('zfar', 20.),
  },
  target: [0., 0., 0.],
  up: [0., 1., 0.],
  auto_rotate: !parse_arg_bool("no-rotate"),
  mouse: {on:false, x:0., y:0.},

  use_MSAA: parse_arg_bool('MSAA'),
  no_gui: parse_arg_bool('no-gui'),
  dbg: { trace: 0, timing: false,
         ortho: parse_arg_bool('ortho'),
         animate_light: parse_arg_bool('animate-light'),
         show_sm: kShowMaps[0],
         no_object: parse_arg_bool('no-object'),
       },
};

////////////////////////////////////////////////////////////////////////////////
// GUI setup

const GUI_change = async () => { await init({}); }  // parameter changed
const GUI_reload = async () => { await init({poly:true}); }

const GUI_init = () => {
  canvas.width  = parse_arg("w", innerWidth * .9);
  canvas.height = parse_arg("h", innerHeight * .8);

  if (params.no_gui) {
    render.gui = undefined;
    return;
  }
  render.gui = new lil.GUI({container: document.getElementById('#main-area'),
                            name: 'Curl Noise'});
  render.gui.add(params, 'poly', Object.keys(kPolys)).name('base polyhedron').listen().onChange(GUI_reload);
  render.gui.add(params, 'depth', 1, 256, 1).name('sub-div level').listen().onChange(GUI_reload);
//  render.gui.add(params, 'noise', Object.keys(kNoise)).listen().onChange(GUI_change);
  render.gui.add(params, 'noise_amp', 0., 20.).name('noise amplitude').listen().onChange(GUI_change);
  render.gui.add(params, 'wireframe').name('wireframe').listen().onChange(GUI_reload);
  render.gui.add(params, 'spherify').name('spherify').listen();
  render.gui.add(params, 'post_proc').name('post_processing').listen();
//  render.gui.add(params, 'use_MSAA').name('multisampling').listen().onChange(() => init({textures:true}));
  render.gui.add(params, 'funky').name('funky!').listen().onChange(GUI_reload);
  const light_folder = render.gui.addFolder('light').close();
  light_folder.addColor(params, 'light_color').name('color').listen();
  light_folder.add(params, 'specular', 0., 2., 0.01).name('specular').listen();
  light_folder.add(params, 'nb_shadow_samples', 1., 256., 1.).name('shadow samples').listen();
  light_folder.add(params, 'shadow_extent', 1., 64., 1.).name('shadow extent').listen();
  light_folder.add(params, 'shadow_jitter', 0., 10., .01).name('shadow jitter').listen();
  const cam_folder = render.gui.addFolder('camera').close();
  cam_folder.add(params.cam, 'fov', 0., 180., 5.).listen();
  cam_folder.add(params.cam, 'dist', 0.0001, 5., 0.01).name('distance').listen();
  cam_folder.add(params.cam, 'theta', 0., 360., 1.).listen();
  cam_folder.add(params.cam, 'phi', -180., 180., 1.).listen();
  cam_folder.add(params.cam, 'znear', 0.0001, 10., 0.01).listen();
  cam_folder.add(params.cam, 'zfar', 0.0001, 10., 0.01).listen();
  const model_folder = render.gui.addFolder('model').close();
  model_folder.add(params.model, 'theta', 0., 360., 1.).listen();
  model_folder.add(params.model, 'phi', -180., 180., 1.).listen();
  model_folder.add(params, 'auto_rotate').name('auto rotate').listen();
  const dbg_folder = render.gui.addFolder('Debug').close();
  dbg_folder.add(params.dbg, 'trace', 0, 3, 1).name('trace level').listen();
  dbg_folder.add(params.dbg, 'timing').name('print timing').listen();
  dbg_folder.add(params.dbg, 'ortho').name('ortho view').listen();
  dbg_folder.add(params.dbg, 'animate_light').name('animate light').listen();
  dbg_folder.add(params.dbg, 'show_sm', kShowMaps).name('map shown:').listen().onChange(GUI_change);
  dbg_folder.add(params.dbg, 'no_object').name('hide object').listen();
  render.gui.add(render, 'txt_info').name('info').listen().disable();

  render.gui.domElement.style.top = '5%';
  render.gui.domElement.style.right = '3%';

  do_resize();
}

function GUI_Get(name) {
  for (const c of render.gui.controllersRecursive()) {
    if (c.property == name) return c;
  }
  return undefined;
}

////////////////////////////////////////////////////////////////////////////////
// event handling

window.addEventListener('pointermove', (event) => {
  if (event.target != canvas) return;
//  event.preventDefault();
  const bounds = canvas.getBoundingClientRect();
  const mouse_x = (event.clientX - bounds.left) / canvas.width;
  const mouse_y = (event.clientY -  bounds.top) / canvas.height;
  if (params.mouse.on) {
    if (event.shiftKey) {
      params.model.phi   += (params.mouse.y - mouse_y) * 140.;
      params.model.theta += (params.mouse.x - mouse_x) * 140.;
    } else {
      params.cam.phi   += (params.mouse.y - mouse_y) * 140.;
      params.cam.theta += (params.mouse.x - mouse_x) * 140.;
    }
  }
  params.mouse.x = mouse_x;
  params.mouse.y = mouse_y;
}, false);
window.addEventListener('pointerdown', (event) => {
  if (event.target == canvas) params.mouse.on = true;
});
window.addEventListener('pointerup', (event) => {
  params.mouse.on = false;
});
window.addEventListener('wheel', (event) => {
  if (event.target != canvas) return;
  event.preventDefault();
  const change_factor = (event.wheelDelta > 0) ? 1.05 : 1. / 1.05;
  if (event.shiftKey) {
    params.model.scale *= change_factor;
    params.model.scale = Math.max(Math.min(params.model.scale, 4.0), 0.1);
  } else {
    params.cam.dist *= change_factor;
    params.cam.dist = Math.max(Math.min(params.cam.dist, 12.0), 0.1);
  }
}, { passive: false });

window.addEventListener('keyup', (e) => {
//  console.log(e.keyCode);
  if (e.keyCode == 70) {
    params.funky = !params.funky;
    params.depth = params.funky ? 30 : 256;
    GUI_reload();
  } else if (e.keyCode == 87) {
    params.wireframe = !params.wireframe;
    GUI_reload();
  }
});

window.addEventListener("resize", (e) => {
  canvas.width = window.innerWidth * .9;
  canvas.height = window.innerHeight * .8;
  do_resize();
});

function do_resize() {
  const pcanvas = document.getElementById("progress-canvas")
  pcanvas.width = .93 * canvas.width;
  init_textures(render);
}

////////////////////////////////////////////////////////////////////////////////
////// WebGPU init //////

const trace = (level, ...args) => {
  if (params.dbg.trace > level) console.log(args.join(' '));
}

function Oops(e) {
  // document.body.innerHTML = `Oops! <pre>${e}</pre>`;
  const side_canvas = document.querySelector("#side-canvas");
  side_canvas.style.display = 'inline-block';
  side_canvas.width = canvas.width * .8;
  const ctx = side_canvas.getContext('2d');
  ctx.fillStyle = '#f33';
  ctx.font = "bold 20px Arial";
  ctx.fillText('Oops!', 15, 30);
  ctx.font = "bold 12px Arial";
  ctx.fillText(e, 15, 55);
  throw Error(e);
}

const GPU_init = async () => {
  navigator.gpu || Oops("WebGPU not supported.");
  console.log("Navigator has GPU");

  const adapter = await navigator.gpu.requestAdapter();
  adapter || Oops("Couldn’t request WebGPU adapter.");
  console.log("WebGPU Adapter ok");

  render.device = await adapter.requestDevice();
  render.device || Oops("Couldn’t request WebGPU logical device.");
  console.log("WebGPU Device acquired.");

  function onDeviceError(event) {
    console.log("Something bad happened! Error type:", event.error.constructor.name);
    console.log("Error message:", event.error.message);
    if (render.device != undefined) {
      render.device.destroy();
      render.device = undefined;
    }
    stop_animation();
    Oops("Error caught while constructing the WebGPU device. See console.");
  }
  render.device.addEventListener('uncapturederror', onDeviceError);

  render.textureFormat = navigator.gpu.getPreferredCanvasFormat();
  render.target = [{
    format: render.textureFormat,
    blend: {
      color: {srcFactor: 'one', dstFactor: 'one-minus-dst-alpha', operation: 'add'},
      alpha: {srcFactor: 'one', dstFactor: 'one', operation: 'add'},
    },
  },];

  ctx.configure({device: render.device,
                 format: render.textureFormat,
                 usage: GPUTextureUsage.RENDER_ATTACHMENT | GPUTextureUsage.COPY_SRC,
                 alphaMode: 'premultiplied', });
}

////////////////////////////////////////////////////////////////////////////////
// Pipelines & Shaders (the cool stuff!)

const VertexIndexBuffer = [  // common index buffer
  { arrayStride: 4,
    stepMode: 'instance',
    attributes: [ { shaderLocation: 0, offset: 0, format: 'uint32', }, ],
  },
];

const struct_code = `
  struct Model {
    model: mat4x3f,
    view: mat4x4f,
    proj: mat4x4f,      // projection * view
    inv_proj: mat4x4f,  // inverse of 'proj'
  };
  struct Light {
    proj: mat4x4f,
    pos: vec4f,
    color: u32,
  };
  struct Params {
    dim:  vec2f,   // screen dimension
    focal: vec2f,
    znear: f32,
    zfar:  f32,
    time:  f32,
    noise_amp:   f32,
    nb_idx: f32,
    nb_faces: f32,
    spherify: f32,
    specular: f32,
    nb_shadow_samples: f32,
    shadow_extent: f32,
    shadow_jitter: f32,
  };
  struct Out {
    @builtin(position) position: vec4f,
    @location(0) uv: vec2f,
    @location(1) @interpolate(flat) color: vec4f,
    @location(2) normal: vec4f,
    @location(3) pos3d: vec4f,
    @location(4) lpos: vec4f,  // light-depth position
  };
  struct Pos {
    p: vec3f,
    n: vec3f,
  };
`;
const screen_code = `
  fn ScreenToTexture(s: vec2f) -> vec2f {   // from [-1,1]^2 to [0,1]^2
    return vec2f(.5, .5) + vec2f(.5, -.5) * s;
  }
  fn WorldFromScreen(uv : vec2f, w: f32) -> vec3f {
    let ndc = vec4f(uv, w, 1.0);
    let world_c = model.inv_proj * ndc;
    return world_c.xyz / world_c.w;
  }
`;

const group_0_code = `
  @group(0) @binding(0) var<uniform> model: Model;
  @group(0) @binding(1) var<uniform> light: Light;
  @group(0) @binding(2) var<uniform> params: Params;
`;
const group_1_code = `
  @group(1) @binding(0) var<storage, read> vtx: array<vec4f>;
  @group(1) @binding(1) var<storage, read> faces: array<array<u32, 3>>;
  @group(1) @binding(2) var<storage, read> uv: array<vec2f>;
`;
const group_2_code = `
  @group(2) @binding(0) var light_depth: texture_depth_2d;
  @group(2) @binding(1) var cmp_sampler: sampler_comparison;
  @group(2) @binding(2) var depth_sampler: sampler;
`;
// displacement noise
const noise_code = `
    const ex = vec3i(1,0,0);
    const ey = vec3i(0,1,0);
    const ez = vec3i(0,0,1);

    fn Hash_1f_1f(x: f32) -> f32 {
      var v = fract(x * .3351);
      v *= v + 33.33;
      v *= v + v;
      return fract(v);
    }
    fn Hash_3f_3f(x: vec3f) -> vec3f {
      var v = fract(x);
      v += dot(v, v.yxz + 32.41);
      return fract((v.xxy + v.yzz) * v.zyx);
    }
    fn Hash1f(p: u32) -> f32 {
      var P = (p << 13) ^ p;
      P = P * (P * P * 15731 + 789221) + 1376312589;
      return bitcast<f32>((P >> 9) | 0x3f800000) - 1.;
    }
    fn Hash3f(p: u32) -> vec3f {
      return vec3f(Hash1f(p), Hash1f(p + 1423), Hash1f(p + 124453));
    }
    fn noise1f(p: vec3i) -> f32 { return Hash1f(u32(dot(p, vec3i(3, 113, 311)))); }
    fn lerp(p: vec3i, alpha: f32) -> f32 { return mix(noise1f(p), noise1f(p + ex), alpha); }
    fn noise1d(p: vec3f) -> f32 {
      let X = vec3i(floor(p));
      let dX = fract(p);
      let n00 = lerp(X, dX.x);
      let n10 = lerp(X + ey, dX.x);
      let n01 = lerp(X + ez, dX.x);
      let n11 = lerp(X + ey + ez, dX.x);
      let m0 = mix(n00, n10, dX.y);
      let m1 = mix(n01, n11, dX.y);
      return mix(m0, m1, dX.z);
    }
    fn noise3d(p: vec3f) -> vec3f {
      return vec3f(noise1d(p),
                   noise1d(p * vec3f(1.03, 0.98, 1.07)),
                   noise1d(p * vec3f(2.01, 0.97, 0.99)));
    }
`;
const displace_code = `
    fn rotation_matrix(axis: vec3f, angle: f32) -> mat3x3f {
      let c = cos(angle);
      let S = axis * sin(angle);
      let C = axis * (1. - c);
      return mat3x3f(vec3f(C.x * axis + vec3f(   c, -S.z,  S.y)),
                     vec3f(C.y * axis + vec3f( S.z   , c, -S.x)),
                     vec3f(C.z * axis + vec3f(-S.y,  S.x,    c)));
    }
    fn fnoise(p: vec3f) -> vec3f {
      let m = rotation_matrix(normalize(vec3f(.4, .3, -.1)), .1);
      var P = p;
      var               out  =        noise3d(P);
//      P = m * P * 2.02; out += .500 * noise3d(P);
//      P = m * P * 2.05; out += .250 * noise3d(P);
//      P = m * P * 1.98; out += .125 * noise3d(P);
      return out;
    }
    // Rodrigues's formula: https://en.wikipedia.org/wiki/Rodrigues%27_rotation_formula
    fn rotate3(p: vec3f, axis: vec3f, angle: f32) -> vec3f {
      // return cos(angle) * p + sin(angle) * cross(axis, p) + (1. - cos(angle)) * dot(p, axis) * axis;
      return rotation_matrix(axis, angle) * p;
    }
    fn Move(p: vec3f, phase: vec3f) -> vec3f {
      let axis = normalize(fnoise(p * 2.53 + phase));
      let angle = 2. * 3.1415926 * noise1d(p * 3.01 + phase);
      return p + rotate3(p, axis, angle) * params.noise_amp;
    }
    fn MakeOrthogonal(v: vec3f) -> vec3f {   // http://sam.hocevar.net/blog/2013/09/
      if (abs(v.x) > abs(v.z)) { return normalize(vec3f(-v.y, v.x, 0.)); }
      return normalize(vec3f(0., -v.z, v.y));
    }
    fn Displace(p: ptr<function, Pos>, t: f32) {
      let phase = vec3f(t, t * 1.01, t * .96);
      let P = (*p).p;
      let N = (*p).n;
      const eps : f32 = 1e-3;
      let t1 = MakeOrthogonal(N);   // tangent
      let t2 = cross(N, t1);        // bi-tangent
      let p0 = Move(P, phase);
      let p1 = Move(P + t1 * eps, phase);
      let p2 = Move(P + t2 * eps, phase);
      let n0 = normalize(cross(p1 - p0, p2 - p0));
      (*p).p = p0;
      (*p).n = n0;
    }
    fn GetPos(vtx_idx: u32, face_idx: u32) -> Pos {
      let face = faces[face_idx];
      let p0 = vtx[face[0]].xyz;
      let p1 = vtx[face[1]].xyz;
      let p2 = vtx[face[2]].xyz;
      let n = normalize(cross(p1 - p0, p2 - p1));
      let m = mat3x3f(p0, p1, p2);
      let UV = uv[vtx_idx];
      let w = vec3f(UV, 1. - UV.x - UV.y);
      // interpolate to p0 * alpha + p1 * beta + p2 * gamma;
      // (and maybe project on the unit sphere):
      var p : Pos;
      p.p = m * w;
      p.n = n;
      if (params.spherify > 0.) {
        p.p = normalize(p.p);
        p.n = -p.p;
      }
      Displace(&p, params.time * 0.002);         // + rotational noise
      p.p = model.model * vec4f(p.p, 1.);
      p.n = model.model * vec4f(p.n, 0.);   // no scaling, so transp(inv(m)) = m
      return p;
    }
`;

function create_poly_pipeline(render) {
  const vtx_code = `
    ${struct_code}
    ${group_0_code}
    ${group_1_code}

    ${noise_code}
    ${displace_code}

    @vertex fn vtx_main(@builtin(vertex_index) vtx_idx: u32,
                        @builtin(instance_index) face_idx: u32,  ) -> Out {
      let p = GetPos(vtx_idx, face_idx);
      let pos3d = model.view * vec4f(p.p, 1.);
      let vpos = model.proj * vec4f(p.p, 1.);
      let normal = normalize(model.view * vec4f(p.n, 0.));

      var output : Out;
      output.position = vpos;
      output.pos3d = pos3d;
      output.normal = normal;
      output.uv = uv[vtx_idx];
      output.color = vec4f(Hash3f(face_idx), 1.);
      return output;
    }`;
  const fragment_code = `
    @fragment fn frag_main(s: Out) -> @location(0) vec4f {
      let light_pos = model.view * light.pos;
      let ldir = normalize(light_pos.xyz - s.pos3d.xyz);
      let r = normalize(reflect(s.pos3d, s.normal).xyz);
      var d = max(0., -dot(ldir, s.normal.xyz));  // diffuse
      d += params.specular * pow(max(0., dot(r, ldir)), 60.);   // specular highlight
      let v = normalize(s.pos3d.xyz);
      var color = .2 * s.color + d * unpack4x8unorm(light.color);
      var sil = 1. - smoothstep(.12, .13, abs(dot(v, s.normal.xyz)));  // silhouette
      color += sil * vec4f(1., .2, .3, 1.);
      return vec4f(color.rgb, 1.);
    }
  `;

  const vtx_module = render.device.createShaderModule(
    { code: vtx_code + fragment_code });
  render.pipeline = render.device.createRenderPipeline({
    layout: 'auto',
    vertex:   { module: vtx_module, entryPoint: 'vtx_main',  buffers: VertexIndexBuffer, },
    fragment: { module: vtx_module, entryPoint: 'frag_main', targets: render.target, },
    primitive: {
      topology: 'triangle-strip',
      stripIndexFormat: 'uint32',
      cullMode: params.funky ? 'none' : 'front',
    },
    depthStencil: {
      depthWriteEnabled: true,
      depthCompare: 'greater',
      format: 'depth24plus',
    },
    multisample: { count: (params.use_MSAA ? 4 : 1), },
  });
  render.bind_group_0 = render.device.createBindGroup({
    layout: render.pipeline.getBindGroupLayout(0),
    entries: render.GPU.uniform_entries,
  });
  render.bind_group_1 = render.device.createBindGroup({
    layout: render.pipeline.getBindGroupLayout(1),
    entries: render.GPU.base_entries,
  });
}

function create_cube_pipeline(render) {   // draw the surrending cube box
  const vtx_code = `
    ${struct_code}
    ${group_0_code}
    const kVtxs = array<u32, 24>(  // 6 faces, each 4 vtx (triangle strip)
        0, 1, 2, 3,  4, 6, 5, 7,  0, 4, 1, 5,  3, 7, 2, 6,  0, 2, 4, 6,  3, 1, 7, 5);
    const kNormals = array<vec4f, 6>(
        vec4f( 0.,-1., 0., 0.), vec4f( 0., 1., 0., 0.),
        vec4f( 0., 0.,-1., 0.), vec4f( 0., 0., 1., 0.),
        vec4f(-1., 0., 0., 0.), vec4f( 1., 0., 0., 0.));
    const kColors = array<vec4f, 6>(
        vec4f( 0., 1., 0., 1.), vec4f( .0, .6, .0, 1.),
        vec4f( 0., 0., 1., 1.), vec4f( .0, .0, .6, 1.),
        vec4f( 1., 0., 0., 1.), vec4f( .6, .0, .0, 1.));
    @vertex fn vtx_main(@builtin(vertex_index) vtx: u32,
                        @builtin(instance_index) face: u32) -> Out {
      _ = params.dim;
      let id = kVtxs[vtx + face * 4];
      var pos = vec3f(1., 1., 1.) * 3.;
      if ((id & 1) != 0) { pos.x = -pos.x; }
      if ((id & 2) != 0) { pos.z = -pos.z; }
      if ((id & 4) != 0) { pos.y = -pos.y; }
      var output : Out;
      output.pos3d = vec4f(pos, 1.);
      output.position = model.proj * output.pos3d;
      output.normal = kNormals[face];
      output.color = kColors[face];
      return output;
    }`;
  const fragment_code = `
    @fragment fn frag_main(s: Out) -> @location(0) vec4f {
      let ldir = light.pos.xyz - s.pos3d.xyz;
      let d = max(0., dot(ldir, s.normal.xyz)) * pow(length(ldir), -1.2);
      let lcol = s.color + d * unpack4x8unorm(light.color);
      return vec4f(lcol.rgb, 1.);
    }
  `;

  const vtx_module = render.device.createShaderModule(
    { code: vtx_code + fragment_code });
  render.cube_pipeline = render.device.createRenderPipeline({
    layout: 'auto',
    vertex:   { module: vtx_module, entryPoint: 'vtx_main', },
    fragment: { module: vtx_module, entryPoint: 'frag_main', targets: render.target, },
    primitive: {
      topology: 'triangle-strip',
      stripIndexFormat: 'uint32',
      cullMode: 'back',
    },
    depthStencil: {
      depthWriteEnabled: true,
      depthCompare: 'greater',
      format: 'depth24plus',
    },
    multisample: { count: (params.use_MSAA ? 4 : 1), },
  });
  render.cube_bind_group_0 = render.device.createBindGroup({
    layout: render.cube_pipeline.getBindGroupLayout(0),
    entries: render.GPU.uniform_entries,
  });
}

function create_post_pipeline(render) {
  const vtx_code = `
    ${struct_code}
    ${group_0_code}
    @group(1) @binding(0) var zbuf: texture_depth_2d;
    @group(1) @binding(1) var screen: texture_2d<f32>;
    @group(1) @binding(2) var screen_sampler: sampler;
    ${group_2_code}  // light-depth

    const kVtx = array<vec4f, 3>(  // screen quad
        vec4f( 3., -1., 0., 1.), vec4f( -1., 3., 0., 1.), vec4f(-1.,-1., 0., 1.));
    @vertex fn vtx_main(@builtin(vertex_index) vtx: u32) -> Out {
      let pos = kVtx[vtx];
      var output : Out;
      output.position = pos;
      output.uv = pos.xy;
      return output;
    }`;
  const fragment_code = `
    ${screen_code}
    ${noise_code}
    fn GetHalo(pos_screen: vec2f) -> f32 {
      let plight_3d = model.view * light.pos;
      let plight_2d = model.proj * light.pos;
      if (plight_2d.w < params.znear) { return 0.; }
      let plight_screen = plight_2d.xy / plight_2d.w;  // in [-1,1] ^ 2
      let plight_txt = ScreenToTexture(plight_screen);
      let plight_depth = textureLoad(zbuf, vec2i(floor(plight_txt * params.dim)), 0);
      var dlight = exp(-30. * length(plight_screen - pos_screen));
      dlight *= step(plight_depth / plight_2d.z, 1.);
      return dlight;
    }
    fn Blur(pos: vec2f, max_size: f32) -> vec3f {
      let size : f32 = 8.;
      var col = vec4f(0.);
      for (var y : f32 = -size; y <= size; y += 1) {
        for (var x : f32 = -size; x <= size; x += 1) {
          let off = vec2f(x, y);
          let coeff = exp(-length(off) / max_size);
          col += coeff * textureSample(screen, screen_sampler, pos + off / params.dim);
        }
      }
      return col.rgb / col.a;
    }
    fn Shadow(pos3d: vec3f) -> vec3f {
      _ = cmp_sampler;
      let light_uv = light.proj * vec4f(pos3d, 1.);
      let light_pos = light_uv.xyz / light_uv.w;
      let light_screen = ScreenToTexture(light_pos.xy); // in [0,1]^2
      let l_depth = textureSample(light_depth, depth_sampler, light_screen);
      var d = 0.;
      var w = 0.;
      let nb_samples = params.nb_shadow_samples;
      let sample_dist = params.shadow_extent / sqrt(nb_samples);
      let sample_unit = 1. / vec2f(textureDimensions(light_depth));
      var sqrt_n = 0.;   // sqrt_n is an approx of sqrt(n)
      const kGoldenAngle = 2.399963229;  // https://en.wikipedia.org/wiki/Golden_angle
      const kRot = mat2x2f( cos(kGoldenAngle), sin(kGoldenAngle),
                           -sin(kGoldenAngle), cos(kGoldenAngle));
      var sample_dir = vec2f(0., sample_dist);
      sample_dir += (Hash_3f_3f(pos3d).xy - vec2f(.5, .5)) * params.shadow_jitter;
      let l_ref = light_pos.z + 0.001;
      for (var n = 0.; n < nb_samples; n += 1.) {
        sqrt_n += 1. / (1. + sqrt_n);
        sample_dir = kRot * sample_dir;
        let pos = light_screen + sqrt_n * sample_dir * sample_unit;
        let l_depth = textureSample(light_depth, depth_sampler, pos);
        // occlusion if l_depth < l_ref
        let delta = l_ref - l_depth;
        let weight = 1.; // l_ref / l_depth;
        d += step(0., delta) * weight;
        w += weight;
      }
      d = max(.2, min(d / w, 1.));
      if (light_uv.w < 0) { d = 1.; }
      return vec3f(d, d, d);
    }

    @fragment fn frag_main(s: Out) -> @location(0) vec4f {
      // debug: if (length(s.uv) > 0.5) { discard; }
      let pos = ScreenToTexture(s.uv);
      var col = Blur(pos, /*max_size = */0.01 + 4. * dot(s.uv, s.uv));

      var screen_w = textureLoad(zbuf, vec2i(floor(pos * params.dim)), 0);
      let pos3d = WorldFromScreen(s.uv, screen_w);
      col *= Shadow(pos3d);
      col += unpack4x8unorm(light.color).rgb * GetHalo(s.uv);
      return vec4f(col, 1.);
    }
  `;

  const vtx_module = render.device.createShaderModule(
    { code: vtx_code + fragment_code });
  render.post_pipeline = render.device.createRenderPipeline({
    layout: 'auto',
    vertex: { module: vtx_module, entryPoint: 'vtx_main', },
    fragment: {
      module: vtx_module,
      entryPoint: 'frag_main',
      targets: render.target,
    },
    primitive: {
      topology: 'triangle-list',
      cullMode: 'none',
    },
    multisample: { count: 1, },
  });
  render.post_bind_group_0 = render.device.createBindGroup({
    layout: render.post_pipeline.getBindGroupLayout(0),
    entries: render.GPU.uniform_entries,
  });
  render.post_bind_group_1 = render.device.createBindGroup({
    layout: render.post_pipeline.getBindGroupLayout(1),
    entries: [
      { binding: 0, resource: render.depth_texture.createView(), },
      { binding: 1, resource: render.post_texture.createView(), },
      { binding: 2, resource:
          render.device.createSampler({magFilter: "linear", minFilter: "linear" }),
      },
    ],
  });
  render.post_bind_group_2 = render.device.createBindGroup({
    layout: render.post_pipeline.getBindGroupLayout(2),
    entries: render.GPU.light_entries,
  });
}

function create_wireframe_pipeline(render) {
  const code = `
    ${struct_code}
    ${group_0_code}
    ${group_1_code}

    ${noise_code}
    ${displace_code}

    @vertex fn vtx_main(@builtin(vertex_index) vtx_idx: u32,
                        @builtin(instance_index) face_idx: u32,  ) -> Out {
      _ = light.proj;
      let p = GetPos(vtx_idx, face_idx);
      var output : Out;
      output.position = model.proj * vec4f(p.p, 1.);
      let g = f32(face_idx) / f32(params.nb_faces) + .8;
      let color = abs(noise3d(vec3f(g, 1., g) * 32.153)) * .8 + .5;
      output.color = vec4f(color, 1.);
      return output;
    }
    @fragment fn frag_main(s: Out) -> @location(0) vec4f {
      return vec4f(s.color.rgb * s.position.w, 1.);
    }
  `;

  const vtx_module = render.device.createShaderModule({ code: code });
  render.pipeline = render.device.createRenderPipeline({
    layout: 'auto',
    vertex: {
      module: vtx_module,
      entryPoint: 'vtx_main',
      buffers: VertexIndexBuffer,
    },
    fragment: {
      module: vtx_module,
      entryPoint: 'frag_main',
      targets: render.target,
    },
    primitive: {
      topology: 'line-strip',
      stripIndexFormat: 'uint32',
      cullMode: 'none',
    },
    depthStencil: {
      depthWriteEnabled: true,
      depthCompare: 'greater',
      format: 'depth24plus',
    },
    multisample: { count: (params.use_MSAA ? 4 : 1), },
  });
  render.bind_group_0 = render.device.createBindGroup({
    layout: render.pipeline.getBindGroupLayout(0),
    entries: render.GPU.uniform_entries,
  });
  render.bind_group_1 = render.device.createBindGroup({
    layout: render.pipeline.getBindGroupLayout(1),
    entries: render.GPU.base_entries,
  });
}

function create_light_pipeline(render) {
  const shadow_code = `
    ${struct_code}
    ${group_0_code}
    ${group_1_code}

    ${noise_code}
    ${displace_code}

    @vertex fn vtx_main(@builtin(vertex_index) vtx_idx: u32,
                        @builtin(instance_index) face_idx: u32,  )
        -> @builtin(position) vec4f {
      var p = GetPos(vtx_idx, face_idx);
      return light.proj * vec4f(p.p, 1.);
    }
  `;
  const shadow_module = render.device.createShaderModule({ code: shadow_code });
  render.light_pipeline = render.device.createRenderPipeline({
    layout: 'auto',
    vertex: { module: shadow_module, entryPoint: 'vtx_main', buffers: VertexIndexBuffer, },
    primitive: {
      topology: params.wireframe ? 'line-strip' : 'triangle-strip',
      stripIndexFormat: 'uint32',
      cullMode: (params.wireframe || params.funky) ? 'none' : 'front',
    },
    depthStencil: {
      depthWriteEnabled: true,
      depthCompare: 'greater',
      format: 'depth32float',
    },
    multisample: { count: 1, },
  });
  render.light_bind_group_0 = render.device.createBindGroup({
    layout: render.light_pipeline.getBindGroupLayout(0),
    entries: render.GPU.uniform_entries,
  });
  render.light_bind_group_1 = render.device.createBindGroup({
    layout: render.light_pipeline.getBindGroupLayout(1),
    entries: render.GPU.base_entries,
  });
}

function create_show_sm_pipeline(render) {
  if (params.dbg.show_sm == kShowMaps[0]) {
    render.show_sm_pipeline = undefined;
    render.show_sm_bind_group = undefined;
    return;
  }
  const show_sm_code = `
    @group(0) @binding(0) var depth_map: texture_depth_2d;
    @group(0) @binding(1) var depth_sampler: sampler;
    const kVtx = array<vec4f, 3>(  // screen quad
        vec4f( 3., -1., 0., 1.), vec4f( -1., 3., 0., 1.), vec4f(-1.,-1., 0., 1.));
    @vertex fn vtx_main(@builtin(vertex_index) vtx: u32) -> @builtin(position) vec4f {
      return kVtx[vtx];
    }
    @fragment fn frag_main(@builtin(position) position : vec4f) -> @location(0) vec4f {
      const kReduction = 2.5;
      let uv = (position.xy * kReduction) / vec2f(textureDimensions(depth_map));
      if (any(uv >= vec2(1.))) { discard; }
      let l_depth = textureSample(depth_map, depth_sampler, uv);
      return vec4f(1. - 0.001 / l_depth, 0., 0., 1.);
    }
  `;

  const module = render.device.createShaderModule({ code: show_sm_code });
  render.show_sm_pipeline = render.device.createRenderPipeline({
    layout: render.device.createPipelineLayout({
              bindGroupLayouts: [
                render.device.createBindGroupLayout({
                  entries: [
                    { binding: 0, visibility: GPUShaderStage.FRAGMENT, texture: { sampleType: 'depth', } },
                    { binding: 1, visibility: GPUShaderStage.FRAGMENT, sampler: { type: 'filtering', } },
                  ],
                }),
              ],
            }),
    vertex: { module: module, entryPoint: 'vtx_main', },
    fragment: { module: module, entryPoint: 'frag_main', targets: render.target, },
    primitive: { topology: 'triangle-list', cullMode: 'none', },
    multisample: { count: 1, },
  });
  render.show_sm_bind_group = render.device.createBindGroup({
    layout: render.show_sm_pipeline.getBindGroupLayout(0),
    entries:
      [ { binding: 0,
          resource: (params.dbg.show_sm == kShowMaps[1]) ? render.light_depth.createView()
                                                         : render.depth_texture.createView(), },
        { binding: 1, resource: render.device.createSampler({}), }, ],
  });
}

function create_pipelines(render) {
  render.device || Oops("Can't create pipelines without a device!");
  if (params.wireframe) create_wireframe_pipeline(render);
  else create_poly_pipeline(render);
  create_cube_pipeline(render);
  create_post_pipeline(render);
  create_light_pipeline(render);
  create_show_sm_pipeline(render);
}

////////////////////////////////////////////////////////////////////////////////
// Create the data buffers

async function init_textures(render) {
  if (render.multisample_texture != undefined) {
    render.multisample_texture.destroy();
    render.multisample_texture = undefined;
  }
  if (params.use_MSAA) {
    render.multisample_texture = render.device.createTexture({
      label: 'multisample',
      size: [canvas.width, canvas.height],
      sampleCount: 4,
      format: render.textureFormat,
      usage: GPUTextureUsage.RENDER_ATTACHMENT,
    });
  }
  render.depth_texture = render.device.createTexture({
    label: 'depth',
    size: [canvas.width, canvas.height],
    format: 'depth24plus',
    usage: GPUTextureUsage.RENDER_ATTACHMENT | GPUTextureUsage.TEXTURE_BINDING,
    sampleCount: (params.use_MSAA ? 4 : 1),
  });
  render.post_texture = render.device.createTexture({
    label: 'post',
    size: [canvas.width, canvas.height],
    format: render.textureFormat,
    sampleCount: (params.use_MSAA ? 4 : 1),
    usage:
      GPUTextureUsage.TEXTURE_BINDING | GPUTextureUsage.COPY_DST | GPUTextureUsage.RENDER_ATTACHMENT,
  });

  render.light_depth = render.device.createTexture({
    label: 'light-depth',
    size: [params.sm_size, params.sm_size, 1],
    format: 'depth32float',
    usage: GPUTextureUsage.RENDER_ATTACHMENT | GPUTextureUsage.TEXTURE_BINDING,
  });
  render.GPU.light_entries = [
    { binding: 0, resource: render.light_depth.createView(), },
    { binding: 1, resource: render.device.createSampler({ compare: 'greater', }), },
    { binding: 2, resource: render.device.createSampler({
            addressModeU: "clamp-to-edge", addressModeV: "clamp-to-edge",
            magFilter: "linear", minFilter: "linear", mipmapFilter: "linear",
    }), },
  ];

  if (render.gui) {
//    GUI_Get('light').enable(params.shadows);
  }
}

// END OF GPU PART
////////////////////////////////////////////////////////////////////////////////

function compute_frame_params() {
  // Model rotation and scaling
  render.model = multiply4(
    multiply4(rotation([0.,-1., 0.], params.model.theta * Math.PI / 180.),
              rotation([0., 0., 1.], params.model.phi * Math.PI / 180.)),
    id4([params.model.scale, params.model.scale, params.model.scale]));

  // Camera view
  const theta = params.cam.theta * Math.PI / 180.;
  const phi = params.cam.phi * Math.PI / 180.;
  const cam_pos = [ params.cam.dist * Math.cos(theta) * Math.cos(phi),
                    params.cam.dist *                   Math.sin(phi),
                    params.cam.dist * Math.sin(theta) * Math.cos(phi), ];
  render.view = look_at(cam_pos, params.target, params.up);

  // Camera projection
  const aspect = canvas.width / canvas.height;
  render.fx = 1. / Math.tan(params.cam.fov * Math.PI / 360.);
  render.fy = aspect * render.fx;
  const proj =
    params.dbg.ortho ? ortho(render.fx, render.fy, params.cam.znear, params.cam.zfar)
                     : perspective(render.fx, render.fy, params.cam.znear, params.cam.zfar);
  render.proj = multiply4(proj, render.view);

  // Light position
  render.light_pos = new Float32Array(params.light_pos);
  if (params.dbg.animate_light) {
    render.light_pos =
      multiply(rotation([0., 1., 0.], .3 * render.tick * Math.PI / 180.), render.light_pos);
  }
//  const light_proj = ortho(1., 1., 0., 5.);
  const light_proj = perspective(1., 1., 0.01, 5.);
  const light_view = look_at(render.light_pos, params.target, params.up);
  render.light_proj = multiply4(light_proj, light_view);

  const l_r = (params.light_color >> 16) & 0xff;
  const l_g = (params.light_color >>  8) & 0xff;
  const l_b = (params.light_color >>  0) & 0xff;
  render.light_color = new Uint8Array([l_r, l_g, l_b, 0xff]);
}

////////////////////////////////////////////////////////////////////////////////
// CPU -> GPU transfer

function transmit_uniforms() {
  render.device.queue.writeBuffer(render.GPU.m_uniforms,  0 * 4, render.model);
  render.device.queue.writeBuffer(render.GPU.m_uniforms, 16 * 4, render.view);
  render.device.queue.writeBuffer(render.GPU.m_uniforms, 32 * 4, render.proj);
  render.device.queue.writeBuffer(render.GPU.m_uniforms, 48 * 4, inverse(render.proj));

  render.device.queue.writeBuffer(render.GPU.l_uniforms,  0 * 4, render.light_proj);
  render.device.queue.writeBuffer(render.GPU.l_uniforms, 16 * 4, render.light_pos);
  render.device.queue.writeBuffer(render.GPU.l_uniforms, 20 * 4, render.light_color);

  render.device.queue.writeBuffer(
    render.GPU.p_uniforms, 0 * 4,
      new Float32Array([ canvas.width, canvas.height,
                         render.fx, render.fy,
                         params.cam.znear, params.cam.zfar,
                         render.tick,
                         params.noise_amp / 50.,
                         render.nb_idx,
                         render.nb_faces,
                         params.spherify,
                         params.specular,
                         params.nb_shadow_samples,
                         params.shadow_extent,
                         params.shadow_jitter, ]));
}

////////////////////////////////////////////////////////////////////////////////
// Animation loop

async function frame() {
  const time_stamp = performance.now();
  if (render.time_stamp) {
    const delta_t = time_stamp - render.time_stamp;
    if (delta_t > 1.) {
      const new_fps = 1000. / delta_t;
      render.fps = Math.round(render.fps * 0.8 + new_fps * 0.2);
    }
    document.getElementById("fps").innerText = render.fps.toFixed(1) + " fps";
  }
  render.time_stamp = time_stamp;

  performance.mark("webgpu start");

  compute_frame_params();

  transmit_uniforms();

  const encoder = render.device.createCommandEncoder();

  if (params.dbg.timing) console.time("GPU");

  if (params.do_shadow) {
    const light_depth_view = render.light_depth.createView({label: 'LIGHT-DEPTH'});
    const light_pass_descriptor = {
      colorAttachments: [],
      depthStencilAttachment: {
        view: light_depth_view,
        depthClearValue: 0.0, depthLoadOp: 'clear', depthStoreOp: 'store',
      },
    };
    const light_pass = encoder.beginRenderPass(light_pass_descriptor);
    light_pass.setPipeline(render.light_pipeline);
    light_pass.setBindGroup(0, render.light_bind_group_0);
    light_pass.setBindGroup(1, render.light_bind_group_1);
    light_pass.setVertexBuffer(0, render.GPU.vtx);
    light_pass.setIndexBuffer(render.GPU.idx, 'uint32');
    light_pass.drawIndexed(render.nb_idx, render.nb_faces);
    light_pass.end();
  }

  const canvas_view = ctx.getCurrentTexture().createView({label: 'CANVAS'});
  const post_texture_view = render.post_texture.createView({label: 'POST-PROC'});
  const render_view = params.post_proc ? post_texture_view : canvas_view;

  if (render.nb_idx > 0) {
    const pass_descriptor = {
      colorAttachments: [
        { view: undefined,
          resolveTarget: undefined,
          clearValue: {r:0., g:0., b:0., a:0.}, loadOp: 'clear', storeOp: 'store', },
      ],
      depthStencilAttachment: {
        view: render.depth_texture.createView(),
        depthClearValue: 0.0, depthLoadOp: 'clear', depthStoreOp: 'store',
      },
    };

    if (params.use_MSAA) {
      const MSAA_view = render.multisample_texture.createView({label: 'MULTISAMPLE'});
      pass_descriptor.colorAttachments[0].view = MSAA_view;
      pass_descriptor.colorAttachments[0].resolveTarget = render_view;
    } else {
      pass_descriptor.colorAttachments[0].view = render_view;
    }
    if (!params.dbg.no_object) {
      const render_pass = encoder.beginRenderPass(pass_descriptor);
      render_pass.setPipeline(render.pipeline);
      render_pass.setBindGroup(0, render.bind_group_0);
      render_pass.setBindGroup(1, render.bind_group_1);
      render_pass.setVertexBuffer(0, render.GPU.vtx);
      render_pass.setIndexBuffer(render.GPU.idx, 'uint32');
      render_pass.drawIndexed(render.nb_idx, render.nb_faces);
      render_pass.end();
    }

    pass_descriptor.depthStencilAttachment.depthLoadOp = 'load';
    pass_descriptor.colorAttachments[0].loadOp = 'load';

    if (params.show_box) {
      const render_pass = encoder.beginRenderPass(pass_descriptor);
      render_pass.setPipeline(render.cube_pipeline);
      render_pass.setBindGroup(0, render.cube_bind_group_0);
      render_pass.draw(4, 6);
      render_pass.end();
    }
  }
  if (params.post_proc) {
    const post_pass_descriptor = {
      colorAttachments: [
        { view: canvas_view,
          clearValue: {r:0., g:0., b:0., a:0.}, loadOp: 'load', storeOp: 'store', },
      ],
    };
    const render_pass = encoder.beginRenderPass(post_pass_descriptor);
    render_pass.setPipeline(render.post_pipeline);
    render_pass.setBindGroup(0, render.post_bind_group_0);
    render_pass.setBindGroup(1, render.post_bind_group_1);
    render_pass.setBindGroup(2, render.post_bind_group_2);
    render_pass.draw(3);
    render_pass.end();
  }
  if (params.do_shadow && params.dbg.show_sm != kShowMaps[0]) {
    const show_sm_pass_descriptor = {
      colorAttachments: [
        { view: canvas_view,
          clearValue: {r:0., g:0., b:0., a:0.}, loadOp: 'load', storeOp: 'store', },
      ],
    };
    const render_pass = encoder.beginRenderPass(show_sm_pass_descriptor);
    render_pass.setPipeline(render.show_sm_pipeline);
    render_pass.setBindGroup(0, render.show_sm_bind_group);
    render_pass.draw(3);
    render_pass.end();
  }

  render.device.queue.submit([encoder.finish()]);

  if (params.dbg.timing) console.timeEnd("GPU");
  performance.mark("webgpu end");
  performance.measure("webgpu", "webgpu start", "webgpu end");

  if (params.auto_rotate) params.model.theta -= 0.07;
  ++render.tick;
  render.loop_id = requestAnimationFrame(frame);
}

function stop_animation() {
  if (render.loop_id != undefined) {
    cancelAnimationFrame(render.loop_id);
    render.loop_id = undefined;
  }
}

////////////////////////////////////////////////////////////////////////////////

var render = {  /* Run-time data: device, uniforms, pipeline... */
  device: undefined,
  textureFormat: undefined,
  target: undefined,

  GPU: {   // data sent to GPU
    vtx:     null,     // base vtx
    faces:   null,     // faces
    idx:     null,     // per-face tesselation sub-idx
    uv:      null,     // barycentric coordinate of sub-idx
    colors:    null,   // u32
    uniforms:  null,
    uniform_entries: null,
    base_entries: null,
    light_entries: null,
    dbg_plane: null,
  },
  nb_vtx: 0,
  nb_faces: 0,
  nb_idx: 0,

  pipeline: null,
  light_pipeline: null,

  // per-frame params
  model: undefined,
  view: undefined,
  proj: undefined,
  light_pos: undefined,
  light_proj: undefined,
  light_color: undefined,
  fx: undefined,
  fy: undefined,

  // side info
  fps: 60.,
  time_stamp: undefined,
  txt_info: "",
  loop_id: undefined,  // id for animation loop
  tick: 0.,

  gui: undefined,
};

////////////////////////////////////////////////////////////////////////////////
// Sub-divisions

function MakeSubUV(depth) {
  const UVs = [];
  for (let i = 0; i <= depth; ++i) {
    for (let j = 0; j <= i; ++j) {
      const u = i / depth, v = j / depth;
      UVs.push(u - v, 1 - u);
    }
  }
  return UVs;
}

function TriIdx(i) { return i * (i + 1) / 2; }
function MakeSubIdx(depth) {
  const idx = [];   // This one could be pre-calc'd up to max_depth
  for (let i = 0; i < depth; ++i) {
    const s = TriIdx(i), t = TriIdx(i + 1);
    if (params.wireframe) {
      idx.push(t);
      for (let j = 0; j <= i; ++j) idx.push(s + j, t + j + 1);  // zig-zag
      for (let j = 0; j <= i; ++j) idx.push(t + i - j);
    } else {
      if (params.funky && ((i % 2) == 1)) continue;
      idx.push(t);
      if (i > 0) {
        idx.push(t);
        idx.push(t);
      }
      for (let j = 0; j <= i; ++j) idx.push(s + j, t + j + 1);
      if (i + 1 < depth) idx.push(t + i + 1);  // repeat last
    }
  }
  return idx;
}

async function set_poly(polyhedron_name) {
  const poly = kPolys[polyhedron_name];

  render.nb_vtx = poly.vtx.length / 4;
  render.GPU.vtx = Create_GPU_Buffer(render.device, poly.vtx, GPUBufferUsage.VERTEX);
  render.nb_faces = poly.faces.length / 3;
  render.GPU.faces = Create_GPU_Buffer(render.device, poly.faces, 0, true);

  const uv = MakeSubUV(params.depth);
  const idx = MakeSubIdx(params.depth);
  render.nb_idx = idx.length;
  render.GPU.idx = Create_GPU_Buffer(render.device, idx, GPUBufferUsage.INDEX, true);
  render.GPU.uv = Create_GPU_Buffer(render.device, uv);

  // uniforms buffers
  render.GPU.m_uniforms = render.device.createBuffer({
    size: 64 * 4,
    usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,
  });
  render.GPU.l_uniforms = render.device.createBuffer({
    size: 24 * 4,
    usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,
  });
  render.GPU.p_uniforms = render.device.createBuffer({
    size: 16 * 4,
    usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,
  })
  render.GPU.uniform_entries = [
    { binding: 0, resource: { buffer: render.GPU.m_uniforms, }, },
    { binding: 1, resource: { buffer: render.GPU.l_uniforms, }, },
    { binding: 2, resource: { buffer: render.GPU.p_uniforms, }, },
  ];

  render.GPU.base_entries = [
    { binding: 0, resource: { buffer: render.GPU.vtx, }, },
    { binding: 1, resource: { buffer: render.GPU.faces, }, },
    { binding: 2, resource: { buffer: render.GPU.uv, }, },
  ];

  // Background Cube
  const cube = kPolys['cube'];
  render.GPU.cube_vtx = Create_GPU_Buffer(render.device, cube.vtx, GPUBufferUsage.VERTEX);
  render.GPU.cube_faces = Create_GPU_Buffer(render.device, cube.faces, 0, true);
  render.GPU.cube_entries = [
    { binding: 0, resource: { buffer: render.GPU.uniforms, }, },
  ];

  if (params.dbg.light) {
    const Y = 0.3;
    render.GPU.dbg_plane = Create_GPU_Buffer(render.device,
      new Float32Array([ -1, Y, -1.,  0., 0.,    0.,
                          1, Y, -1.,  1., 0.,    0.,
                         -1, Y,  1.,  0., 1.,    0.,
                          1, Y,  1.,  1., 1.,    0.]),
      GPUBufferUsage.VERTEX);
  }
  render.tick = 0.;
  render.txt_info = "vtx:" + render.nb_vtx + " faces:" + render.nb_faces
                  + " idx:" + render.nb_idx + " uv:" + (uv.length / 2);
}

async function init(what) {
  render.device || Oops("Initialization failed. Is WebGPU supported and " +
                        "<a href='https://github.com/gpuweb/gpuweb/wiki/Implementation-Status'>enabled</a>?");
  stop_animation();

  if (what.poly) {
    await set_poly(params.poly);
  }
  if (what.textures) {
    await init_textures(render);
  }
  create_pipelines(render);

  frame();    // start animation loop
}

async function main() {
  try {
    await GPU_init();
    GUI_init();
    await init({poly:true, textures:true,});
  } catch(e) { Oops(e); }
}

</script>

</body>
</html>
